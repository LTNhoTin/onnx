{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1492b6e7",
   "metadata": {},
   "source": [
    "# Xuất mô hình từ PyTorch sang ONNX và chạy với ONNX Runtime\n",
    "Hướng dẫn này sẽ hướng dẫn cách xuất một mô hình Super Resolution từ PyTorch sang ONNX và kiểm tra với ONNX Runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998748ee",
   "metadata": {},
   "source": [
    "## 1. Cài đặt thư viện cần thiết\n",
    "Chúng ta cần cài đặt PyTorch, ONNX và ONNX Runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4aab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: onnx in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (1.17.0)\n",
      "Requirement already satisfied: onnxruntime in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (1.20.1)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (11.1.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (from onnx) (5.29.3)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (from onnxruntime) (24.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/env_onnx/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision onnx onnxruntime pillow numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f931641",
   "metadata": {},
   "source": [
    "## 2. Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf42ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7794d9",
   "metadata": {},
   "source": [
    "## 3. Định nghĩa mô hình Super Resolution trong PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72dfe3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SuperResolutionNet(nn.Module):\n",
    "    def __init__(self, upscale_factor, inplace=False):\n",
    "        super(SuperResolutionNet, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pixel_shuffle(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv4.weight)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a871f1b",
   "metadata": {},
   "source": [
    "## 4. Tạo mô hình và tải trọng số đã huấn luyện trước"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec294e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperResolutionNet(\n",
       "  (relu): ReLU()\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pixel_shuffle): PixelShuffle(upscale_factor=3)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'\n",
    "torch_model = SuperResolutionNet(upscale_factor=3)\n",
    "map_location = lambda storage, loc: storage\n",
    "torch_model.load_state_dict(model_zoo.load_url(model_url, map_location=map_location))\n",
    "torch_model.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df01b61b",
   "metadata": {},
   "source": [
    "## 5. Xuất mô hình sang định dạng ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "827dbb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = torch.randn(1, 1, 224, 224, requires_grad=True)\n",
    "torch.onnx.export(torch_model, x, \"super_resolution.onnx\", export_params=True, opset_version=10,\n",
    "                  do_constant_folding=True, input_names=['input'], output_names=['output'],\n",
    "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed0e8c",
   "metadata": {},
   "source": [
    "## 6. Kiểm tra mô hình ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f53e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "onnx_model = onnx.load(\"super_resolution.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4736f594",
   "metadata": {},
   "source": [
    "## 7. Chạy mô hình với ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3807d353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mô hình ONNX chạy tốt với ONNX Runtime!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"super_resolution.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "np.testing.assert_allclose(to_numpy(torch_model(x)), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "print(\"Mô hình ONNX chạy tốt với ONNX Runtime!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5473d1ee",
   "metadata": {},
   "source": [
    "## 8. So sánh hiệu suất giữa PyTorch và ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c442d1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference với PyTorch mất 0.03198099136352539 giây\n",
      "Inference với ONNX Runtime mất 0.02173304557800293 giây\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(1, 1, 224, 224, requires_grad=True)\n",
    "\n",
    "start = time.time()\n",
    "torch_out = torch_model(x)\n",
    "end = time.time()\n",
    "print(f\"Inference với PyTorch mất {end - start} giây\")\n",
    "\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "start = time.time()\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "end = time.time()\n",
    "print(f\"Inference với ONNX Runtime mất {end - start} giây\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ce52b",
   "metadata": {},
   "source": [
    "# 9. Mở ảnh và tiền xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ead0d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8039, 0.8039, 0.8039,  ..., 0.7961, 0.7961, 0.7961],\n",
       "          [0.8118, 0.8078, 0.8118,  ..., 0.7922, 0.7922, 0.7922],\n",
       "          [0.8078, 0.8078, 0.8039,  ..., 0.7922, 0.7922, 0.7922],\n",
       "          ...,\n",
       "          [0.6275, 0.6353, 0.6353,  ..., 0.6431, 0.6431, 0.6353],\n",
       "          [0.6353, 0.6353, 0.6353,  ..., 0.6471, 0.6431, 0.6431],\n",
       "          [0.6471, 0.6392, 0.6353,  ..., 0.6471, 0.6471, 0.6431]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"cat.jpg\")\n",
    "\n",
    "resize = transforms.Resize([224, 224])\n",
    "img = resize(img)\n",
    "\n",
    "img_ycbcr = img.convert('YCbCr')\n",
    "img_y, img_cb, img_cr = img_ycbcr.split()\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_y = to_tensor(img_y)\n",
    "img_y.unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841636d9",
   "metadata": {},
   "source": [
    "# 10. Chạy mô hình ONNX trên ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb3a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "img_out_y = ort_outs[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0725f80f",
   "metadata": {},
   "source": [
    "# 11. Hậu xử lý và lưu ảnh kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16f8ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_out_y = Image.fromarray(np.uint8((img_out_y[0] * 255.0).clip(0, 255)[0]), mode='L')\n",
    "final_img = Image.merge(\n",
    "    \"YCbCr\", [\n",
    "        img_out_y,\n",
    "        img_cb.resize(img_out_y.size, Image.BICUBIC),\n",
    "        img_cr.resize(img_out_y.size, Image.BICUBIC),\n",
    "    ]).convert(\"RGB\")\n",
    "\n",
    "final_img.save(\"cat_superres_with_ort.jpg\")\n",
    "img = transforms.Resize([img_out_y.size[0], img_out_y.size[1]])(img)\n",
    "img.save(\"cat_resized.jpg\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_onnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
